{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hate-speach-identification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMzoBAKcsBVoF1kahHhGLM9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahshawaiz/hatespeach-group-identification/blob/master/hate_speach_identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_FPjdN6tKKI",
        "colab_type": "code",
        "outputId": "a897fc4b-bfc0-4e5c-aa15-ee42bd730f0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# # # activate kaggle, mount grdive, download/unzip dataset\n",
        "# import os\n",
        "# import glob\n",
        "\n",
        "# os.environ['KAGGLE_USERNAME'] = \"shahshawaiz\" # username from the json file\n",
        "# os.environ['KAGGLE_KEY'] = \"476e4fb10eef6d9da79358d4df0db985\" # key from the json file\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# # init consts\n",
        "# PATH_HOME = \"/content\"\n",
        "# PATH_GDRIVE = '/content/drive/My Drive/Colab Notebooks/dataset/hate-speach/train'\n",
        "# FILE_TYPE = {\n",
        "#     \"1\": \"datasets\",\n",
        "#     \"2\": \"competitions\"\n",
        "# }\n",
        "# FILES = {\n",
        "#     FILE_TYPE[\"1\"] : [\n",
        "#         \"jdpaletto/glove-global-vectors-for-word-representation\"\n",
        "#     ],\n",
        "#     FILE_TYPE[\"2\"]: [\n",
        "#         \"jigsaw-unintended-bias-in-toxicity-classification\"\n",
        "#     ]\n",
        "# }\n",
        "\n",
        "# # iterate files and download\n",
        "# for file_type, paths in FILES.items():\n",
        "#   for path in paths:\n",
        "#     try:\n",
        "#       # move and delete\n",
        "#       !kaggle \"$file_type\" download \"$path\"\n",
        "      \n",
        "#       archives = glob.glob(\"/content/*.zip\")\n",
        "#       for download in archives:\n",
        "#         file_dir = download.strip('.zip')\n",
        "#         !unzip -qq \"$download\"\n",
        "#         !mv -n \"$file_dir\" \"$PATH_GDRIVE\"/\n",
        "#         !mv -n \"$file_dir\"/ \"$PATH_GDRIVE\"/\n",
        "#         !rm -rf \"$download\" \"$file_dir\"\n",
        "\n",
        "#       non_archives = glob.glob(\"/content/*.txt\") + glob.glob(\"/content/*.csv\")\n",
        "#       for download in non_archives:\n",
        "#         !mv -n \"$download\" \"$PATH_GDRIVE\"/\n",
        "#         !rm -rf \"$download\"\n",
        "\n",
        "\n",
        "#     except OSError as e:\n",
        "#       print(\"failed download: \", path, file)\n",
        "#       pass\n",
        "\n",
        "# # # drive.flush_and_unmount()   \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLai9C2cEW-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pkgs installation\n",
        "# !pip install tensorflow h5py pyyaml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO7THy4XENa3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "439b3187-a1f0-497d-f9f4-92b7aaaf8635"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_val_score, train_test_split\n",
        "from sklearn.metrics import roc_curve, auc, f1_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "import os\n",
        "\n",
        "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import Dense, Embedding, GlobalMaxPooling1D, Conv1D, Dropout, Activation, SpatialDropout1D, Bidirectional, CuDNNLSTM\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.optimizers import Adam\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "\n",
        "from keras.initializers import Constant\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTzYAmj_Ed0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set env\n",
        "MODEL_VERSION = 'a'\n",
        "PATH = '/content/drive/My Drive/Colab Notebooks/dataset/hate-speach'\n",
        "PATH_GLOVE_100d = PATH + '/train/glove.twitter.27B.100d.txt'\n",
        "PATH_TRAIN = PATH + '/train/train.csv'\n",
        "# PATH_IMAGES = PATH + '/train'\n",
        "# PATH_METADATA = PATH + '/all_data_info.csv'\n",
        "# PATH_MODEL = PATH + '/models/m-' + MODEL_VERSION + '.h5'\n",
        "# PATH_CHECKPOINT = PATH + '/checkpoints/cp-' + MODEL_VERSION + '.ckpt'\n",
        "# PATH_MISSING_LOG = PATH + '/missing/ms-' + MODEL_VERSION + '.txt'\n",
        "# CHECKPOINT_PERIOD = 3\n",
        "# SLICE_SIZE = 100\n",
        "# NUM_CLASSES = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jOvcBxnETwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# glove embeding routine\n",
        "def get_glove_embedding():\n",
        "    _embeddings_index = {}\n",
        "    f = open(PATH_GLOVE_100d)\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        _embeddings_index[word] = coefs\n",
        "    f.close() \n",
        "    \n",
        "    return _embeddings_index\n",
        "    \n",
        "embeddings_index = get_glove_embedding()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BExKIL5ZFEbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read csv\n",
        "train=pd.read_csv(PATH_TRAIN)\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O0AEn_lFULg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class dist\n",
        "def plot_class_dist(df):\n",
        "    plt.bar(range(0, len(df.columns.values)), df.sum().values, align='center')\n",
        "    plt.ylabel('Classes')\n",
        "    plt.title('Class Distribution')\n",
        "    plt.show()    \n",
        "    \n",
        "def plot_class_dist_b(col_list):\n",
        "    plt.bar(range(0, 4), col_list, align='center')\n",
        "    plt.ylabel('Classes')\n",
        "    plt.title('Class Distribution')\n",
        "    plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJTT7O5dFaUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# resampling\n",
        "def try_underSampling(train):\n",
        "    \n",
        "    #Prepare for under sampling \n",
        "    religion = train[(train.religion == 1)]\n",
        "    print(\"target religion : \",religion.shape)\n",
        "    ethnicity = train[(train.ethnicity == 1)]\n",
        "    print(\"ethnicity: \",ethnicity.shape)\n",
        "    sexualOrientation = train[(train.sexualOrientation == 1)]\n",
        "    print(\"sexualOrientation: \",sexualOrientation.shape)\n",
        "    gender = train[(train.sex == 1)]\n",
        "    print(\"gender: \",gender.shape)\n",
        "    no_hatespeech = train[(train.religion == 0) | (train.ethnicity == 0) | (train.sexualOrientation == 0) | (train.sex == 0)]\n",
        "    print(\"No hatespeech : \",no_hatespeech.shape)\n",
        "    all_together = train[(train.religion == 1) | (train.ethnicity == 1) | (train.sexualOrientation == 1) | (train.sex == 1)]\n",
        "    \n",
        "    religion = religion.sample(1189, replace=True)\n",
        "    ethnicity = ethnicity.sample(1189, replace=True)\n",
        "    sexualOrientation = sexualOrientation.sample(1189, replace=True)\n",
        "    gender = gender.sample(1189, replace=True)\n",
        "    no_hatespeech = no_hatespeech.sample(1189, replace=True)\n",
        "    all_together = all_together.sample(1189, replace=True)\n",
        "\n",
        "    print(\"New target religion : \",religion.shape)\n",
        "    print(\"New ethnicity: \", ethnicity.shape)\n",
        "    print(\"New sexualOrientation: \",sexualOrientation.shape)\n",
        "    print(\"New gender: \",gender.shape)\n",
        "    print(\"New No hatespeech : \",no_hatespeech.shape)\n",
        "    print(\"All : \",all_together.shape)\n",
        "    \n",
        "    train_set = pd.concat([religion, ethnicity, sexualOrientation, gender, no_hatespeech])\n",
        "    train_set = train_set[['id', 'target', 'comment_text', 'religion','ethnicity','sexualOrientation', 'sex', 'tags']]\n",
        "    \n",
        "    return train_set, [religion.shape[0], ethnicity.shape[0], sexualOrientation.shape[0], gender.shape[0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayPw9QFmFeXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encoding routine\n",
        "def one_hot_encode_by_label(dataset, new_col, col_list, threshold_val=0.1):\n",
        "    \n",
        "    for col in col_list:\n",
        "        dataset[new_col] = (\n",
        "            dataset[col] > threshold_val\n",
        "        )*1.0  \n",
        "    return dataset\n",
        "\n",
        "# encode all column/groups\n",
        "religions = [\n",
        "    'atheist',\n",
        "    'buddhist',\n",
        "    'christian',\n",
        "    'hindu',\n",
        "    'jewish',\n",
        "    'muslim',\n",
        "    'other_religion'\n",
        "]\n",
        "train = one_hot_encode_by_label(train, 'religion', religions)\n",
        "\n",
        "#\n",
        "ethnicity = [\n",
        "    'asian',\n",
        "    'black',\n",
        "    'latino',\n",
        "    'white',\n",
        "    'other_race_or_ethnicity'\n",
        "]\n",
        "train = one_hot_encode_by_label(train, 'ethnicity', ethnicity)\n",
        "\n",
        "# \n",
        "sexualOrientation = [\n",
        "    'bisexual',\n",
        "    'heterosexual',\n",
        "    'homosexual_gay_or_lesbian',\n",
        "    'transgender',\n",
        "    'other_sexual_orientation'    \n",
        "]\n",
        "train = one_hot_encode_by_label(train, 'sexualOrientation', sexualOrientation)\n",
        "\n",
        "#\n",
        "sex = [\n",
        "    'male',\n",
        "    'female',\n",
        "    'other_gender' \n",
        "]\n",
        "\n",
        "# run one hot encoding\n",
        "train = one_hot_encode_by_label(train, 'sex', sex)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdcuZfL4Fh-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add tag column\n",
        "train[\"tags\"] = 0\n",
        "train[\"tags\"] = train.apply(lambda x: x['tags'] if x['religion']==0 else x['religion']*0, axis=1)\n",
        "train[\"tags\"] = train.apply(lambda x: x['tags'] if x['ethnicity']==0 else x['ethnicity']*1, axis=1)\n",
        "train[\"tags\"] = train.apply(lambda x: x['tags'] if x['sexualOrientation']==0 else x['sexualOrientation']*2, axis=1)\n",
        "train[\"tags\"] = train.apply(lambda x: x['tags'] if x['sex']==0 else x['sex']*3, axis=1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZI3xcdQFloV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filter data with only hate comments\n",
        "train=train[(train.religion == 1) | (train.ethnicity == 1) | (train.sexualOrientation == 1) | (train.sex == 1)]\n",
        "\n",
        "\n",
        "# run resampling\n",
        "plot_class_dist(train[['religion','ethnicity','sexualOrientation', 'sex']])\n",
        "train, sample_shape = try_underSampling(train)\n",
        "\n",
        "train[['religion','ethnicity','sexualOrientation', 'sex']].sum(axis=0).values\n",
        "\n",
        "plot_class_dist_b(sample_shape)\n",
        "\n",
        "# \n",
        "train.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h2_XBJEF4QG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x,y sepration\n",
        "X = train['comment_text']\n",
        "y = train[['religion','ethnicity','sexualOrientation', 'sex']]\n",
        "train.columns\n",
        "y2 = train['tags']\n",
        "\n",
        "# # train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y2, stratify=y2, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6neO-mp1F8JE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = y_train[[ 'religion','ethnicity','sexualOrientation', 'sex']].values\n",
        "y_test = y_test[[ 'religion','ethnicity','sexualOrientation', 'sex']].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCaQsUg3F_Kv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# init vars\n",
        "max_features = 20000  # number of words we want to keep\n",
        "maxlen = 200  # max length of the comments in the model\n",
        "batch_size = 64  # batch size for the model\n",
        "embedding_dims = 100  # dimension of the hidden variable, i.e. the embedding dimension\n",
        "epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M9Yo-lDGBgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# init tkenizer\n",
        "tok = Tokenizer(num_words=max_features)\n",
        "\n",
        "X_train_org = X_train\n",
        "X_test_org = X_test\n",
        "\n",
        "# fit train/test comments over tokenizer\n",
        "tok.fit_on_texts(list(X_train) + list(X_test))\n",
        "\n",
        "# convert text to sequence\n",
        "x_train = tok.texts_to_sequences(X_train)\n",
        "x_test = tok.texts_to_sequences(X_test)\n",
        "\n",
        "# debug\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "print('Average train sequence length: {}'.format(np.mean(list(map(len, x_train)), dtype=int)))\n",
        "print('Average test sequence length: {}'.format(np.mean(list(map(len, x_test)), dtype=int)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeGxpRTdGCDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = tok.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "num_words = min(max_features, len(word_index)) + 1\n",
        "print(num_words)\n",
        "\n",
        "# init embedding matrix\n",
        "embedding_matrix = np.zeros((num_words, embedding_dims))\n",
        "\n",
        "# for every word token, get vector from glove embeding vecotr (from w2v model)\n",
        "for word, i in word_index.items():\n",
        "    if i > max_features:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # we found the word - add that words vector to the matrix\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        # doesn't exist, assign a random vector\n",
        "        embedding_matrix[i] = np.random.randn(embedding_dims)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNLMu8nmGEcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \n",
        "y_train=y_train[:1209265,:]\n",
        "y_test=y_test[:1209265,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kWAGks-GJJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pad sequences to get equal length vector/comments\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "print(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzJ51wEeGL1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# f1 score routine\n",
        "def f1_score_b(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9SHv-4ZGMV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# confusion matrix routine\n",
        "def get_confusion_matrix(model, x_test, y_true):\n",
        "    y_pred = model.predict(x_test)\n",
        "    y_pred = (y_pred > 0.5) #greater than 0.50 on scale 0 to 1\n",
        "\n",
        "    from sklearn.metrics import classification_report\n",
        "    return classification_report(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV6KmlsKGQZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lstm bidirectional with glove embeding model creation \n",
        "def create_model_feedforward(\n",
        "    f1_score=f1_score_b,\n",
        "    n_input=5,\n",
        "    n_output=4,    \n",
        "    output_activation='softmax', \n",
        "    loss='binary_crossentropy', \n",
        "    optimizer='adam'\n",
        "):\n",
        "    \n",
        "    # model init\n",
        "    model = Sequential()\n",
        "    \n",
        "    # layer embeding     \n",
        "    model.add(\n",
        "        Embedding(\n",
        "            max_features, \n",
        "            embedding_dims, \n",
        "            input_length=maxlen, \n",
        "            embeddings_initializer=\"uniform\"\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    # layer pooling for dim reducntion\n",
        "    model.add(\n",
        "        GlobalMaxPooling1D()\n",
        "    )\n",
        "    \n",
        "    #      \n",
        "    model.add(\n",
        "        Dense(n_input, activation='relu')\n",
        "    )\n",
        "    \n",
        "    # output     \n",
        "    model.add(\n",
        "        Dense(n_output, activation=output_activation)\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss=loss,\n",
        "        optimizer=optimizer,\n",
        "        metrics=['accuracy', f1_score])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S_Py3BqGdcH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = create_model_feedforward()\n",
        "model1.summary()\n",
        "\n",
        "history_ff = model1.fit(x_train, y_train, verbose=1, epochs=epochs)\n",
        "\n",
        "print(get_confusion_matrix(model1,x_train, y_train))\n",
        "\n",
        "# print(X_test)\n",
        "# X_test = tok.texts_to_sequences(X_test)\n",
        "# dat_test = pd.DataFrame([\"taking jobs\", \"muslims\", \"jews\", \"christians\", \"muslims are evil people\", \"jews are stupid\"], columns = ['comment_text'])['comment_text']\n",
        "# dat_test_test1 = tok.texts_to_sequences(dat_test)\n",
        "# x_test_1 = sequence.pad_sequences(dat_test_test1, maxlen=maxlen)\n",
        "# y_pred = model1.predict(x_test_1)\n",
        "# # y_pred_df = pd.DataFrame(y_pred)\n",
        "\n",
        "# model1_f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "# model1_acc = accuracy_score(y_test2, y_pred2, normalize=True)\n",
        "# print('f1:', model1_f1, 'acc', model1_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxLA_uLmGg8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lstm bidirectional with glove embeding model creation \n",
        "def create_model_org_lstm_bidir_glove(\n",
        "    f1_score=f1_score_b,\n",
        "    n1_lstm=64,\n",
        "    n2_lstm=32,\n",
        "    n_output=4,\n",
        "    spatial_dropout=0.2, \n",
        "    pre_output_dropout=0.25, \n",
        "    output_neurons=4, \n",
        "    output_activation='softmax', \n",
        "    loss='categorical_crossentropy', \n",
        "    optimizer='adam'):\n",
        "    \n",
        "    # init model\n",
        "    model = Sequential()\n",
        "    \n",
        "    # layer embeding\n",
        "    model.add(Embedding(\n",
        "        num_words, \n",
        "        embedding_dims, \n",
        "        input_length=maxlen,\n",
        "        embeddings_initializer=Constant(embedding_matrix),\n",
        "        trainable=True        \n",
        "    ))\n",
        "\n",
        "    # layer dropout for gerneralizatoin (drops entire 1D feature maps instead of individual elements)\n",
        "    model.add(SpatialDropout1D(spatial_dropout))\n",
        "    \n",
        "    # Bidirectional: ?,   CuDNNLSTM: better/fast implementation of LSTM\n",
        "    model.add(Bidirectional(CuDNNLSTM(n1_lstm, return_sequences=True)))\n",
        "    \n",
        "    #     \n",
        "    model.add(Bidirectional(CuDNNLSTM(n2_lstm)))\n",
        "    \n",
        "    # \n",
        "    model.add(Dropout(pre_output_dropout))\n",
        "    \n",
        "    # layer output\n",
        "    model.add(Dense(units=4, activation=output_activation))\n",
        "    \n",
        "    model.compile(loss=loss,\n",
        "          optimizer=optimizer,\n",
        "          metrics=['accuracy', f1_score])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8pWydj2GjbP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #  lstm bidirectional with glove embeding compilation and fitting\n",
        "# model2 = create_model_org_lstm_bidir_glove()\n",
        "# model2.summary()\n",
        "# history_lstm = model2.fit(x_train, y_train, verbose=1, epochs=10)\n",
        "\n",
        "# print(get_confusion_matrix(model2,x_train, y_train))\n",
        "\n",
        "# path_write = os.path.join('../input/','model2.h5')\n",
        "# print(path_write)\n",
        "\n",
        "# outp = model2.save(path_write)\n",
        "# print(outp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gadUwYGyGmUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#NB implementation\n",
        "def create_naive_bayes():\n",
        "\n",
        "#     tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
        "#     features = tfidf.fit_transform(train.comment_text).toarray()\n",
        "\n",
        "    model = Pipeline([('vect', CountVectorizer()),\n",
        "                   ('tfidf', TfidfTransformer()),\n",
        "                   ('clf', MultinomialNB()),\n",
        "                  ])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSBombaVGoZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  nb\n",
        "model3 = create_naive_bayes()\n",
        "model3.fit(X_train2, y_train2)\n",
        "\n",
        "# f2 score\n",
        "y_pred2 = model3.predict(X_test2)\n",
        "model3_f1 = f1_score(y_test2, y_pred2, average=\"weighted\")\n",
        "model3_acc = accuracy_score(y_test2, y_pred2, normalize=True)\n",
        "print('f1:', model3_f1, 'acc', model3_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjcuD0cwGqEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# svm implementation\n",
        "def create_svm():\n",
        "    \n",
        "    model = Pipeline([\n",
        "        ('vect', CountVectorizer()),\n",
        "        ('tfidf', TfidfTransformer()),\n",
        "        ('clf', SGDClassifier(loss='hinge', penalty='l2')) # hinge loss functino for linear SVM\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkrzGHPUGtDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# acm\n",
        "model4 = create_svm()\n",
        "model4.fit(X_train2, y_train2)\n",
        "\n",
        "# f2 score\n",
        "y_pred2 = model4.predict(X_test2)\n",
        "model4_f1 = f1_score(y_test2, y_pred2, average='weighted')\n",
        "model4_acc = accuracy_score(y_test2, y_pred2, normalize=True)\n",
        "print('f1:', model4_f1, 'acc', model4_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdgkhcj6Gv0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # testing predictions\n",
        "# y_precit = model2.predict(x_test)\n",
        "# len(x_test), y_test, len(y_test), y_precit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF6vfpcfG6fA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# examples: religion','ethnicity','sexualOrientation', 'sex']\n",
        "\n",
        "dat_test = pd.DataFrame([\"muslims\", \"jews\", \"christians\", \"muslims are evil people\", \"jews are stupid\"], columns = ['comment_text'])['comment_text']\n",
        "dat_test = tok.texts_to_sequences(dat_test)\n",
        "dat_test = sequence.pad_sequences(dat_test, maxlen=maxlen)\n",
        "y_pred = model1.predict(dat_test)\n",
        "y_pred_df = pd.DataFrame(y_pred)\n",
        "print('relgion (1)', y_pred_df)\n",
        "\n",
        "dat_test = pd.DataFrame([\"immigrants are taking jobs\", \"immigrants should go back\", \"i hate color black\", \"i hate color white\", \"chinese are stupid\"], columns = ['comment_text'])['comment_text']\n",
        "dat_test = tok.texts_to_sequences(dat_test)\n",
        "dat_test = sequence.pad_sequences(dat_test, maxlen=maxlen)\n",
        "y_pred = model1.predict(dat_test)\n",
        "y_pred_df = pd.DataFrame(y_pred)\n",
        "print('ethinicity (2)', y_pred_df)\n",
        "\n",
        "\n",
        "dat_test = pd.DataFrame([\"bisexual\", \"gay\", \"lesbian\", \"i hate homosexuals\", \"transgenders are stupid\"], columns = ['comment_text'])['comment_text']\n",
        "dat_test = tok.texts_to_sequences(dat_test)\n",
        "dat_test = sequence.pad_sequences(dat_test, maxlen=maxlen)\n",
        "y_pred = model1.predict(dat_test)\n",
        "y_pred_df = pd.DataFrame(y_pred)\n",
        "print('sexual orientation (3)', y_pred_df)\n",
        "\n",
        "dat_test = pd.DataFrame([\"women\", \"men\", \"feminism\", \"Kill woman society\", \"Bloddy female group\"], columns = ['comment_text'])['comment_text']\n",
        "dat_test = tok.texts_to_sequences(dat_test)\n",
        "dat_test = sequence.pad_sequences(dat_test, maxlen=maxlen)\n",
        "y_pred = model1.predict(dat_test)\n",
        "y_pred_df = pd.DataFrame(y_pred)\n",
        "print('gender (4)', y_pred_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0-i84oKG7DJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# examples: religion','ethnicity','sexualOrientation', 'sex']\n",
        "\n",
        "dat_test = pd.DataFrame([\"muslims\", \"jews\", \"christians\", \"muslims are evil people\", \"jews are stupid\"], columns = ['comment_text'])['comment_text']\n",
        "dat_test = tok.texts_to_sequences(dat_test)\n",
        "dat_test = sequence.pad_sequences(dat_test, maxlen=maxlen)\n",
        "y_pred = model2.predict(dat_test)\n",
        "y_pred_df = pd.DataFrame(y_pred)\n",
        "print('relgion (1)', y_pred_df)\n",
        "\n",
        "dat_test = pd.DataFrame([\"immigrants are taking jobs\", \"immigrants should go back\", \"i hate color black\", \"i hate color white\", \"chinese are stupid\"], columns = ['comment_text'])['comment_text']\n",
        "dat_test = tok.texts_to_sequences(dat_test)\n",
        "dat_test = sequence.pad_sequences(dat_test, maxlen=maxlen)\n",
        "y_pred = model2.predict(dat_test)\n",
        "y_pred_df = pd.DataFrame(y_pred)\n",
        "print('ethinicity (2)', y_pred_df)\n",
        "\n",
        "\n",
        "dat_test = pd.DataFrame([\"bisexual\", \"gay\", \"lesbian\", \"i hate homosexuals\", \"transgenders are stupid\"], columns = ['comment_text'])['comment_text']\n",
        "dat_test = tok.texts_to_sequences(dat_test)\n",
        "dat_test = sequence.pad_sequences(dat_test, maxlen=maxlen)\n",
        "y_pred = model2.predict(dat_test)\n",
        "y_pred_df = pd.DataFrame(y_pred)\n",
        "print('sexual orientation (3)', y_pred_df)\n",
        "\n",
        "dat_test = pd.DataFrame([\"women\", \"men\", \"feminism\", \"Kill woman society\", \"Bloddy female group\"], columns = ['comment_text'])['comment_text']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU11npUtG9L_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model 1 HP grid space\n",
        "n_input=[5,10,15]\n",
        "n_output=[4] \n",
        "output_activation = ['softmax', 'relu', 'sigmoid']\n",
        "optimizer = ['adam', 'sgd']\n",
        "loss=['binary_crossentropy']\n",
        "\n",
        "# # hyperparamter gird space\n",
        "hyperparamter_space = dict(\n",
        "#     n_input=n_input,\n",
        "#     n_output=n_output,\n",
        "    output_activation=output_activation,\n",
        "\toptimizer=optimizer,\n",
        "# \tloss=loss,\n",
        ")\n",
        "\n",
        "# hyperparamter optimization using scikit learn GridSearch CV\n",
        "def optimize_hyperparamters(build_fn, x_train, y_train, hyperparamter_space=hyperparamter_space):\n",
        "\n",
        "    # init classifier\n",
        "    model = KerasClassifier(\n",
        "        build_fn=build_fn, verbose=0\n",
        "    )\n",
        "\n",
        "    # gridsearch using hyperparamer space        \n",
        "    grid = GridSearchCV(\n",
        "        estimator=model, \n",
        "        param_grid=hyperparamter_space, \n",
        "        cv=3\n",
        "    )\n",
        "\n",
        "    # model fitting        \n",
        "    grid_result = grid.fit(\n",
        "        x_train, \n",
        "        y_train\n",
        "    )\n",
        "    # print best fit \n",
        "    print(\"Best Params: %s; Score: %f\" % (grid_result.best_params_, grid_result.best_score_))\n",
        "\n",
        "    means = grid_result.cv_results_['mean_test_score']\n",
        "    params = grid_result.cv_results_['params']\n",
        "\n",
        "    # print all combinations\n",
        "    for mean, param in zip(means, params):\n",
        "        print(\"%f @ %r\" % (mean, param))\n",
        "\n",
        "    return grid_result.best_params_\n",
        "\n",
        "# get optimized hyperparamter combination\n",
        "best_params = optimize_hyperparamters(\n",
        "    create_model_feedforward,\n",
        "    x_train, \n",
        "    y_train\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czoaYpDqHB72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # lstm bidirectional with glove embeding model creation \n",
        "# Model 2 HP grid space\n",
        "# optimizer = ['softmax','adam', 'sgd']\n",
        "n1_lstm = [32, 64]\n",
        "n2_lstm = [64, 96]\n",
        "# n_input=[5,10,15]\n",
        "# spatial_dropout=[0.2, 0.4, 0.6]\n",
        "# pre_output_dropout=[0.25, 0.45, 0.65],   \n",
        "# output_neurons = [4]\n",
        "# output_activation = ['softmax','relu', 'sigmoid']\n",
        "# optimizer = ['adam', 'sgd']\n",
        "# loss=['binary_crossentropy']\n",
        "\n",
        "# # hyperparamter gird space\n",
        "hyperparamter_space = dict(\n",
        "    n1_lstm=n1_lstm,\n",
        "    n2_lstm=n2_lstm,\n",
        "#     spatial_dropout=spatial_dropout,\n",
        "#     pre_output_dropout=pre_output_dropout\n",
        ")\n",
        "\n",
        "# hyperparamter optimization using scikit learn GridSearch CV\n",
        "def optimize_hyperparamters(build_fn, x_train, y_train, hyperparamter_space=hyperparamter_space):\n",
        "\n",
        "    # init classifier\n",
        "    model = KerasClassifier(\n",
        "        build_fn=build_fn, verbose=0\n",
        "    )\n",
        "\n",
        "    # gridsearch using hyperparamer space        \n",
        "    grid = GridSearchCV(\n",
        "        estimator=model, \n",
        "        param_grid=hyperparamter_space, \n",
        "        cv=3\n",
        "    )\n",
        "\n",
        "    # model fitting        \n",
        "    grid_result = grid.fit(\n",
        "        x_train, \n",
        "        y_train\n",
        "    )\n",
        "    # print best fit \n",
        "    print(\"Best Params: %s; Score: %f\" % (grid_result.best_params_, grid_result.best_score_))\n",
        "\n",
        "    means = grid_result.cv_results_['mean_test_score']\n",
        "    params = grid_result.cv_results_['params']\n",
        "\n",
        "    # print all combinations\n",
        "    for mean, param in zip(means, params):\n",
        "        print(\"%f @ %r\" % (mean, param))\n",
        "\n",
        "    return grid_result.best_params_\n",
        "\n",
        "# get optimized hyperparamter combination\n",
        "best_params = optimize_hyperparamters(\n",
        "    create_model_org_lstm_bidir_glove,\n",
        "    x_train, \n",
        "    y_train\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osBpa7DVHDqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training history\n",
        "df=pd.DataFrame({\n",
        "    'epoch': range(0,history_lstm.params['epochs']), \n",
        "    'm1': history_lstm.history['f1_score_b'], \n",
        "    'm2': history_ff.history['f1_score_b']\n",
        "})\n",
        " \n",
        "plt.plot( 'epoch', 'm1', data=df, marker='', color='red', linewidth=2)\n",
        "plt.plot( 'epoch', 'm2', data=df, marker='', color='blue', linewidth=2)\n",
        "\n",
        "plt.title('Training History')\n",
        "plt.ylabel('F1')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['FF', 'LSTM'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOs9d-DRHGXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # ROC/AOC curve\n",
        "# false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\n",
        "# roc_auc = auc(false_positive_rate, true_positive_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}